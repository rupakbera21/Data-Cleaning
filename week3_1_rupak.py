# -*- coding: utf-8 -*-
"""Week3_1_Rupak.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tn33h1OQ7OiO9HZjzGfScsAf-W_G_RFt

#**Data cleaning and manipulation using Pandas and Numpy**
##**Dataset:**
1. Data-cleaning-for-beginners-using-pandas.csv (data)


 **Columns:**
-	Age
-	Salary
-	Rating
-	Location
-	Established
-	Easy Apply

1. Data Cleaning dataset
- Importing the libraries
"""

# importing libraries
import numpy as np
import pandas as pd

"""- Reading the data"""

data = pd.read_csv("/content/drive/MyDrive/Week 3 - Data Cleaning (Pandas) - 1/Data-cleaning-for-beginners-using-pandas.csv")

"""- Printing the dataset"""

data

"""- Copying the dataset (To preserve the content of original dataset)"""

copy_data=data.copy()

"""- Converting the column name to lower case and removing the space"""

copy_data.columns=copy_data.columns.str.lower().str.replace(" ","_")

"""- Printing the first 5 columns of the uncleaned dataset"""

copy_data.head()

"""- Printing the last 5 columns of the uncleaned dataset"""

copy_data.tail()

"""- Getting the shape of the dataset"""

copy_data.shape

"""- Getting more information about the dataset"""

copy_data.info()

"""- Finding the total null values in each columns
 1. isnull() - To find the null values
 2. sum() - To find the sum of all the null values  
"""

copy_data.isnull().sum()

"""- Finding the average age"""

avg_age = copy_data['age'].mean()
avg_age

"""- Replacing the null values with average age
 1. fillna(avg_age) - Replacing the null values with average age
 2. sum() - To round the float values
 3. astype(int) - To convert the datatype to integer  
"""

copy_data['age'] = copy_data.age.fillna(avg_age).round().astype(int)
copy_data.head()

"""- Checking the dataset info"""

copy_data.info()

"""- Removing '$' and Replacing 'k' with '000' using str.replace()"""

copy_data['salary'] = copy_data['salary'].str.replace('$', '').str.replace('k', '000')
copy_data.head()

"""- Splitting the 'salary' column into 'min_salary' and 'max_salary' and converting them to integer type"""

copy_data[['min_salary', 'max_salary']] = copy_data['salary'].str.split('-', expand=True)

# Converting both columns to integers
copy_data['min_salary'] = copy_data['min_salary'].astype(int)
copy_data['max_salary'] = copy_data['max_salary'].astype(int)

# Dropping the 'salary' column
copy_data = copy_data.drop('salary', axis=1)

copy_data.head()

"""- Checking the dataset info"""

copy_data.info()

"""- Counting number of -1.0 present in 'rating' column"""

count_of_minus_one = (copy_data['rating'] == -1.0).sum()
count_of_minus_one

"""- Replacing -1.0 rating with 0.0 rating"""

copy_data['rating'] = copy_data['rating'].replace(-1, 0)
copy_data.head()

"""- Counting number of '-1' in 'established' column"""

count_of_minus_one_established = (copy_data['established'] == -1).sum()
count_of_minus_one_established

"""- Finding the Mode value (Frequently occuring value)
  
  (Here, iloc[1] indexer is used for selection by position)
"""

mode_established = copy_data['established'].mode().iloc[1]
mode_established

"""- Replacing Mode value with '-1' in 'established' column"""

copy_data['established'] = copy_data['established'].replace(-1, mode_established)
copy_data.head()

"""- Formatting String in 'location' column"""

copy_data['location'] = copy_data['location'].replace({'New York,Ny':'New York', 'India,In':'India','India In':'India', 'Australia Aus':'Australia'})
copy_data.head()

"""- Checking the dataset info"""

copy_data.info()

"""- Converting datatype of 'location' column from object to string"""

copy_data['location'] = copy_data['location'].astype('string')
copy_data.info()

"""- Finding the unique values in 'easy_apply' column"""

unique_values_count = copy_data['easy_apply'].unique()
unique_values_count

"""- Necessary replacements
  
  1. From 'TRUE' to True
  2. From '-1' to False
"""

copy_data['easy_apply'] = copy_data['easy_apply'].replace('TRUE', True)

copy_data['easy_apply'] = copy_data['easy_apply'].replace('-1', False)

copy_data.head()

"""- Converting the 'easy_apply' column to Boolean datatype"""

copy_data['easy_apply'] = copy_data['easy_apply'].astype(bool)
#Checking dataset info
copy_data.info()

"""- Found 1 null value in 'rating' column"""

copy_data['rating'].isnull().sum()

"""- Finding the average rating"""

mean_rating=copy_data['rating'].mean()
mean_rating

"""- Replacing the null value with the average rating"""

copy_data['rating'] = copy_data.rating.fillna(mean_rating).round(decimals=1)
copy_data.head()

"""- Checking for null values in the dataset"""

copy_data.isnull().sum()

"""- Checking the dataset info"""

copy_data.info()

"""- Printing the dataset"""

copy_data